import os
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage, ToolMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from app.core.rag import RAGManager
from app.core.keyword_matcher import KeywordMatcher
from app.core.few_shot_manager import FewShotManager
from dotenv import load_dotenv

load_dotenv()

class AgentManager:
    def __init__(self, enable_few_shot=True, enable_direct_retrieval=False):
        # èŽ·å–æ¨¡åž‹æä¾›å•†é…ç½®
        provider = os.getenv("MODEL_PROVIDER", "aliyun").lower()
        self.provider = provider
        self.enable_few_shot = enable_few_shot
        self.enable_direct_retrieval = enable_direct_retrieval  # æ–°å¢žï¼šæ˜¯å¦å¯ç”¨ç›´æŽ¥æ£€ç´¢
        
        # æ ¹æ®æä¾›å•†åˆå§‹åŒ– LLM
        if provider == "groq":
            self.llm = ChatOpenAI(
                model=os.getenv("GROQ_LLM_MODEL", "llama-3.3-70b-versatile"),
                openai_api_base="https://api.groq.com/openai/v1",
                openai_api_key=os.getenv("GROQ_API_KEY")
            )
            print(f"âœ… ä½¿ç”¨ Groq æ¨¡åž‹: {os.getenv('GROQ_LLM_MODEL', 'llama-3.3-70b-versatile')}")
            print("â„¹ï¸  Groq ä½¿ç”¨ç®€åŒ–çš„ RAG æ¨¡å¼ï¼ˆä¸ä½¿ç”¨ Agentï¼‰")
        else:  # é»˜è®¤ä½¿ç”¨é˜¿é‡Œäº‘
            self.llm = ChatOpenAI(
                model=os.getenv("LLM_MODEL", "qwen-plus"),
                openai_api_base="https://dashscope.aliyuncs.com/compatible-mode/v1",
                openai_api_key=os.getenv("DASHSCOPE_API_KEY")
            )
            print(f"âœ… ä½¿ç”¨é˜¿é‡Œäº‘æ¨¡åž‹: {os.getenv('LLM_MODEL', 'qwen-plus')}")
        
        self.rag = RAGManager()
        self.keyword_matcher = KeywordMatcher()
        self.few_shot_manager = FewShotManager() if enable_few_shot else None
        self.last_retrieved_docs = []
        self.used_knowledge_base = False
        self.used_direct_retrieval = False
        self.used_few_shot = False
        self.keyword_matched = False  # æ–°å¢žï¼šæ ‡è®°æ˜¯å¦å‘½ä¸­å…³é”®è¯
        
        # æ‰“å°å…³é”®è¯ç»Ÿè®¡
        stats = self.keyword_matcher.get_statistics()
        print(f"ðŸ“š å·²åŠ è½½ {stats['æ€»å…³é”®è¯æ•°']} ä¸ªå…³é”®è¯")
        if self.enable_direct_retrieval:
            print("ðŸ’¡ å‘½ä¸­å…³é”®è¯å°†ä½¿ç”¨å¢žå¼ºæ£€ç´¢ï¼ˆk=8ï¼‰ï¼Œæé«˜å‡†ç¡®åº¦")
        else:
            print("ðŸ’¡ å…³é”®è¯æ£€æŸ¥å·²ç¦ç”¨ï¼Œæ‰€æœ‰æŸ¥è¯¢ä½¿ç”¨æ ‡å‡†æ£€ç´¢ï¼ˆk=5ï¼‰")
        
        # æ‰“å° Few-Shot ç»Ÿè®¡
        if self.few_shot_manager:
            few_shot_stats = self.few_shot_manager.get_statistics()
            print(f"ðŸ“ å·²åŠ è½½ {few_shot_stats['æ€»ç¤ºä¾‹æ•°']} ä¸ª Few-Shot ç¤ºä¾‹")
            print("ðŸ’¡ Few-Shot å°†ç»Ÿä¸€å›žç­”æ ¼å¼å’Œé£Žæ ¼")

    def create_agent(self):
        # 1. åˆ›å»ºæ£€ç´¢å™¨
        retriever = self.rag.get_retriever()
        
        # 2. å®šä¹‰å·¥å…·å‡½æ•°
        @tool
        def search_knowledge_base(query: str) -> str:
            """æœç´¢æœ¬åœ°çŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯ã€‚å¯¹äºŽä»»ä½•é—®é¢˜ï¼Œéƒ½åº”è¯¥å…ˆä½¿ç”¨æ­¤å·¥å…·æœç´¢çŸ¥è¯†åº“ï¼Œçœ‹æ˜¯å¦æœ‰ç›¸å…³å†…å®¹ã€‚çŸ¥è¯†åº“ä¸­å¯èƒ½åŒ…å«ä¹¦ç±ã€æ–‡æ¡£ã€æŠ€æœ¯èµ„æ–™ç­‰å„ç§å†…å®¹ã€‚"""
            docs = retriever.invoke(query)
            # è®°å½•æ£€ç´¢åˆ°çš„æ–‡æ¡£
            self.last_retrieved_docs = docs
            self.used_knowledge_base = True
            return "\n\n".join([d.page_content for d in docs])

        tools = [search_knowledge_base]

        # 3. åˆ›å»º Agent (æ–°ç‰ˆæœ¬ LangChain è¿”å›žçš„æ˜¯ä¸€ä¸ªç¼–è¯‘åŽçš„å›¾)
        return create_agent(
            model=self.llm,
            tools=tools,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚å¯¹äºŽç”¨æˆ·çš„ä»»ä½•é—®é¢˜ï¼Œä½ éƒ½åº”è¯¥å…ˆä½¿ç”¨ search_knowledge_base å·¥å…·æœç´¢æœ¬åœ°çŸ¥è¯†åº“ã€‚å¦‚æžœçŸ¥è¯†åº“ä¸­æœ‰ç›¸å…³å†…å®¹ï¼Œè¯·åŸºäºŽçŸ¥è¯†åº“å†…å®¹å›žç­”ï¼›å¦‚æžœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œå†ä½¿ç”¨ä½ çš„é€šç”¨çŸ¥è¯†å›žç­”ã€‚"
        )

    def run_simple_rag(self, query: str, keyword_matched=False, book_filter=None):
        """
        ç®€åŒ–çš„ RAG å®žçŽ°ï¼Œä¸ä½¿ç”¨ Agentï¼ˆé€‚ç”¨äºŽ Groqï¼‰
        
        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢
            keyword_matched: æ˜¯å¦å‘½ä¸­å…³é”®è¯ï¼ˆç”¨äºŽä¼˜åŒ–æ£€ç´¢ç­–ç•¥ï¼‰
            book_filter: ä¹¦åè¿‡æ»¤ï¼ˆå¦‚ "çº¢æ¥¼æ¢¦"ï¼‰ï¼Œåªæ£€ç´¢æŒ‡å®šä¹¦ç±
        """
        # é‡ç½®çŠ¶æ€
        self.last_retrieved_docs = []
        self.used_knowledge_base = False
        self.used_few_shot = False
        self.keyword_matched = keyword_matched  # è®°å½•æ˜¯å¦å‘½ä¸­å…³é”®è¯
        
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        # å¦‚æžœå‘½ä¸­å…³é”®è¯ï¼Œå¢žåŠ æ£€ç´¢æ•°é‡ä»¥èŽ·å¾—æ›´å…¨é¢çš„ä¿¡æ¯
        k = 8 if keyword_matched else 5
        
        # å¦‚æžœæŒ‡å®šäº†ä¹¦åè¿‡æ»¤
        if book_filter:
            print(f"ðŸ“š é™å®šæ£€ç´¢èŒƒå›´ï¼š{book_filter}")
            docs = self.rag.search_by_book(query, book_filter, k=k)
        else:
            retriever = self.rag.get_retriever(k=k)
            docs = retriever.invoke(query)
        
        self.last_retrieved_docs = docs
        
        if keyword_matched:
            print(f"ðŸŽ¯ å‘½ä¸­å…³é”®è¯ï¼Œä½¿ç”¨å¢žå¼ºæ£€ç´¢ï¼ˆk={k}ï¼‰")
        
        # 2. æž„å»ºæç¤ºè¯
        if docs:
            self.used_knowledge_base = True
            context = "\n\n".join([doc.page_content for doc in docs])
            
            # ä½¿ç”¨ Few-Shotï¼ˆå¦‚æžœå¯ç”¨ï¼‰
            if self.few_shot_manager:
                self.used_few_shot = True
                prompt = self.few_shot_manager.build_few_shot_prompt(query, context)
            else:
                prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚è¯·åŸºäºŽä»¥ä¸‹çŸ¥è¯†åº“å†…å®¹å›žç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

çŸ¥è¯†åº“å†…å®¹ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·åŸºäºŽä¸Šè¿°çŸ¥è¯†åº“å†…å®¹å›žç­”é—®é¢˜ã€‚å¦‚æžœçŸ¥è¯†åº“å†…å®¹ä¸è¶³ä»¥å›žç­”é—®é¢˜ï¼Œå¯ä»¥ç»“åˆä½ çš„é€šç”¨çŸ¥è¯†è¡¥å……ã€‚"""
        else:
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·å›žç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"""
        
        # 3. è°ƒç”¨ LLM
        messages = [HumanMessage(content=prompt)]
        response = self.llm.invoke(messages)
        
        return response.content
    
    def run_simple_rag_stream(self, query: str, keyword_matched=False, book_filter=None):
        """
        ç®€åŒ–çš„ RAG å®žçŽ°ï¼ˆæµå¼ç‰ˆæœ¬ï¼‰
        
        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢
            keyword_matched: æ˜¯å¦å‘½ä¸­å…³é”®è¯ï¼ˆç”¨äºŽä¼˜åŒ–æ£€ç´¢ç­–ç•¥ï¼‰
            book_filter: ä¹¦åè¿‡æ»¤ï¼ˆå¦‚ "çº¢æ¥¼æ¢¦"ï¼‰ï¼Œåªæ£€ç´¢æŒ‡å®šä¹¦ç±
        
        è¿”å›ž:
            ç”Ÿæˆå™¨ï¼Œé€ä¸ªè¿”å›žæ–‡æœ¬å—
        """
        # é‡ç½®çŠ¶æ€
        self.last_retrieved_docs = []
        self.used_knowledge_base = False
        self.used_few_shot = False
        self.keyword_matched = keyword_matched
        
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        k = 8 if keyword_matched else 5
        
        if book_filter:
            print(f"ðŸ“š é™å®šæ£€ç´¢èŒƒå›´ï¼š{book_filter}")
            docs = self.rag.search_by_book(query, book_filter, k=k)
        else:
            retriever = self.rag.get_retriever(k=k)
            docs = retriever.invoke(query)
        
        self.last_retrieved_docs = docs
        
        if keyword_matched:
            print(f"ðŸŽ¯ å‘½ä¸­å…³é”®è¯ï¼Œä½¿ç”¨å¢žå¼ºæ£€ç´¢ï¼ˆk={k}ï¼‰")
        
        # 2. æž„å»ºæç¤ºè¯
        if docs:
            self.used_knowledge_base = True
            context = "\n\n".join([doc.page_content for doc in docs])
            
            if self.few_shot_manager:
                self.used_few_shot = True
                prompt = self.few_shot_manager.build_few_shot_prompt(query, context)
            else:
                prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚è¯·åŸºäºŽä»¥ä¸‹çŸ¥è¯†åº“å†…å®¹å›žç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

çŸ¥è¯†åº“å†…å®¹ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·åŸºäºŽä¸Šè¿°çŸ¥è¯†åº“å†…å®¹å›žç­”é—®é¢˜ã€‚å¦‚æžœçŸ¥è¯†åº“å†…å®¹ä¸è¶³ä»¥å›žç­”é—®é¢˜ï¼Œå¯ä»¥ç»“åˆä½ çš„é€šç”¨çŸ¥è¯†è¡¥å……ã€‚"""
        else:
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·å›žç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"""
        
        # 3. æµå¼è°ƒç”¨ LLM
        messages = [HumanMessage(content=prompt)]
        for chunk in self.llm.stream(messages):
            if hasattr(chunk, 'content') and chunk.content:
                yield chunk.content
    
    def run_stream(self, query: str):
        """æµå¼è¿è¡Œï¼ˆå…¥å£æ–¹æ³•ï¼‰"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨ç›´æŽ¥æ£€ç´¢
        if self.enable_direct_retrieval:
            should_direct, reason = self.keyword_matcher.should_use_direct_retrieval(query)
            
            if should_direct:
                print(f"ðŸŽ¯ {reason}")
                return self.run_simple_rag_stream(query, keyword_matched=True)
            else:
                print(f"ðŸ¤– {reason}")
        
        # æœªå‘½ä¸­å…³é”®è¯æˆ–æœªå¯ç”¨ç›´æŽ¥æ£€ç´¢
        return self.run_simple_rag_stream(query, keyword_matched=False)

    def direct_retrieval(self, query: str) -> str:
        """
        ç›´æŽ¥æ£€ç´¢æ¨¡å¼ - ä¸ä½¿ç”¨ LLMï¼Œç›´æŽ¥è¿”å›žå‘é‡åº“æ£€ç´¢ç»“æžœ
        é€‚ç”¨äºŽå‘½ä¸­å…³é”®è¯çš„ç®€å•æŸ¥è¯¢
        """
        # é‡ç½®çŠ¶æ€
        self.last_retrieved_docs = []
        self.used_knowledge_base = True
        self.used_direct_retrieval = True
        
        # æ£€ç´¢ç›¸å…³æ–‡æ¡£
        retriever = self.rag.get_retriever()
        docs = retriever.invoke(query)
        self.last_retrieved_docs = docs
        
        if not docs:
            return "æŠ±æ­‰ï¼Œåœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚"
        
        # ç›´æŽ¥è¿”å›žæ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹ï¼ˆä¸ç»è¿‡ LLM åŠ å·¥ï¼‰
        # å–å‰3ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ
        result_parts = []
        for i, doc in enumerate(docs[:3], 1):
            content = doc.page_content.strip()
            source = doc.metadata.get("source", "æœªçŸ¥")
            page = doc.metadata.get("page", "æœªçŸ¥")
            
            result_parts.append(f"ã€ç‰‡æ®µ {i}ã€‘ï¼ˆæ¥æºï¼š{source}ï¼Œé¡µç ï¼š{page}ï¼‰\n{content}")
        
        return "\n\n" + "\n\n".join(result_parts)

    def run(self, query: str):
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨ç›´æŽ¥æ£€ç´¢
        if self.enable_direct_retrieval:
            # å…ˆæ£€æŸ¥æ˜¯å¦å‘½ä¸­å…³é”®è¯
            should_direct, reason = self.keyword_matcher.should_use_direct_retrieval(query)
            
            if should_direct:
                print(f"ðŸŽ¯ {reason}")
                # ä¸å†ç›´æŽ¥è¿”å›žæ£€ç´¢ç»“æžœï¼Œè€Œæ˜¯ä¼ é€’ç»™ LLM å¤„ç†
                # return self.direct_retrieval(query)  # æ—§æ–¹å¼ï¼šç›´æŽ¥è¿”å›ž
                
                # æ–°æ–¹å¼ï¼šå‘½ä¸­å…³é”®è¯æ—¶ä½¿ç”¨å¢žå¼ºæ£€ç´¢ï¼Œä½†ä»é€šè¿‡ LLM å¤„ç†
                if self.provider == "groq":
                    return self.run_simple_rag(query, keyword_matched=True)
                else:
                    # é˜¿é‡Œäº‘ Agent æ¨¡å¼æš‚æ—¶ä¿æŒåŽŸæ ·
                    return self.run_agent_mode(query)
            else:
                print(f"ðŸ¤– {reason}")
        
        # æœªå‘½ä¸­å…³é”®è¯æˆ–æœªå¯ç”¨ç›´æŽ¥æ£€ç´¢
        # Groq ä½¿ç”¨ç®€åŒ–çš„ RAGï¼Œé˜¿é‡Œäº‘ä½¿ç”¨ Agent
        if self.provider == "groq":
            return self.run_simple_rag(query, keyword_matched=False)
        else:
            return self.run_agent_mode(query)
    
    def run_agent_mode(self, query: str):
        """é˜¿é‡Œäº‘ Agent æ¨¡å¼"""
        # é‡ç½®çŠ¶æ€
        self.last_retrieved_docs = []
        self.used_knowledge_base = False
        self.used_direct_retrieval = False
        
        graph = self.create_agent()
        # è°ƒç”¨å›¾ï¼Œè¾“å…¥æ¶ˆæ¯åˆ—è¡¨
        inputs = {"messages": [{"role": "user", "content": query}]}
        result = graph.invoke(inputs)
        # èŽ·å–æœ€åŽä¸€æ¡ AI æ¶ˆæ¯çš„å†…å®¹
        messages = result.get("messages", [])
        if messages:
            return messages[-1].content
        return "æœªèƒ½ç”Ÿæˆå›žå¤ã€‚"
    
    def get_last_retrieval_info(self):
        """èŽ·å–æœ€åŽä¸€æ¬¡æ£€ç´¢çš„è¯¦ç»†ä¿¡æ¯"""
        return {
            "used_knowledge_base": self.used_knowledge_base,
            "used_direct_retrieval": self.used_direct_retrieval,
            "used_few_shot": self.used_few_shot,
            "keyword_matched": self.keyword_matched,  # æ–°å¢žï¼šæ˜¯å¦å‘½ä¸­å…³é”®è¯
            "retrieved_docs_count": len(self.last_retrieved_docs),
            "sources": [
                {
                    "source": doc.metadata.get("source", "æœªçŸ¥"),
                    "page": doc.metadata.get("page", "æœªçŸ¥"),
                    "preview": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content
                }
                for doc in self.last_retrieved_docs
            ]
        }
