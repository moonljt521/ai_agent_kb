"""
æ··åˆæ£€ç´¢å™¨ - æ”¯æŒæœ¬åœ°å‘é‡åº“ + å¤–éƒ¨ API
"""
import os
from typing import List, Dict, Any, Optional
from langchain_core.documents import Document
import requests


class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨ï¼šæœ¬åœ°å‘é‡åº“ + å¤–éƒ¨ API"""
    
    def __init__(self, local_rag_manager, similarity_threshold=0.7):
        """
        åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨
        
        Args:
            local_rag_manager: æœ¬åœ° RAG ç®¡ç†å™¨
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼æ—¶è°ƒç”¨å¤–éƒ¨ API
        """
        self.local_rag = local_rag_manager
        self.similarity_threshold = similarity_threshold
        
        # å¤–éƒ¨ API é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        self.external_api_enabled = os.getenv("EXTERNAL_API_ENABLED", "false").lower() == "true"
        self.external_api_url = os.getenv("EXTERNAL_API_URL", "")
        self.external_api_key = os.getenv("EXTERNAL_API_KEY", "")
        
        print(f"ğŸ”— æ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–")
        print(f"   æœ¬åœ°å‘é‡åº“ï¼šâœ…")
        print(f"   å¤–éƒ¨ APIï¼š{'âœ… å·²å¯ç”¨' if self.external_api_enabled else 'âŒ æœªå¯ç”¨'}")
        if self.external_api_enabled:
            print(f"   ç›¸ä¼¼åº¦é˜ˆå€¼ï¼š{similarity_threshold}")
    
    def retrieve(self, query: str, k: int = 5, book_filter: Optional[str] = None) -> List[Document]:
        """
        æ··åˆæ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢é—®é¢˜
            k: è¿”å›æ–‡æ¡£æ•°é‡
            book_filter: ä¹¦ç±è¿‡æ»¤ï¼ˆä»…æœ¬åœ°ï¼‰
            
        Returns:
            æ–‡æ¡£åˆ—è¡¨
        """
        # 1. å…ˆæŸ¥æœ¬åœ°å‘é‡åº“
        print(f"ğŸ“š æ£€ç´¢æœ¬åœ°å‘é‡åº“...")
        local_docs = self._retrieve_local(query, k, book_filter)
        
        # 2. è¯„ä¼°æœ¬åœ°ç»“æœè´¨é‡
        if local_docs:
            max_similarity = self._get_max_similarity(local_docs)
            print(f"   æœ€é«˜ç›¸ä¼¼åº¦ï¼š{max_similarity:.2f}")
            
            # å¦‚æœæœ¬åœ°ç»“æœè¶³å¤Ÿå¥½ï¼Œç›´æ¥è¿”å›
            if max_similarity >= self.similarity_threshold:
                print(f"   âœ… æœ¬åœ°ç»“æœè´¨é‡è‰¯å¥½ï¼Œä½¿ç”¨æœ¬åœ°æ•°æ®")
                return local_docs
        
        # 3. æœ¬åœ°ç»“æœä¸å¤Ÿå¥½ï¼Œå°è¯•å¤–éƒ¨ API
        if self.external_api_enabled:
            print(f"   âš ï¸  æœ¬åœ°ç»“æœä¸è¶³ï¼ˆç›¸ä¼¼åº¦ < {self.similarity_threshold}ï¼‰ï¼ŒæŸ¥è¯¢å¤–éƒ¨ API...")
            external_docs = self._retrieve_external(query, k)
            
            if external_docs:
                print(f"   âœ… å¤–éƒ¨ API è¿”å› {len(external_docs)} ä¸ªç»“æœ")
                # åˆå¹¶æœ¬åœ°å’Œå¤–éƒ¨ç»“æœ
                return self._merge_results(local_docs, external_docs, k)
            else:
                print(f"   âš ï¸  å¤–éƒ¨ API æ— ç»“æœï¼Œä½¿ç”¨æœ¬åœ°æ•°æ®")
        else:
            print(f"   â„¹ï¸  å¤–éƒ¨ API æœªå¯ç”¨ï¼Œä»…ä½¿ç”¨æœ¬åœ°æ•°æ®")
        
        return local_docs
    
    def _retrieve_local(self, query: str, k: int, book_filter: Optional[str] = None) -> List[Document]:
        """ä»æœ¬åœ°å‘é‡åº“æ£€ç´¢"""
        try:
            if book_filter:
                return self.local_rag.search_by_book(query, book_filter, k=k)
            else:
                retriever = self.local_rag.get_retriever(k=k)
                return retriever.invoke(query)
        except Exception as e:
            print(f"   âŒ æœ¬åœ°æ£€ç´¢å¤±è´¥ï¼š{e}")
            return []
    
    def _retrieve_external(self, query: str, k: int) -> List[Document]:
        """ä»å¤–éƒ¨ API æ£€ç´¢"""
        try:
            # è°ƒç”¨å¤–éƒ¨ API
            response = requests.post(
                self.external_api_url,
                json={
                    "query": query,
                    "k": k
                },
                headers={
                    "Authorization": f"Bearer {self.external_api_key}",
                    "Content-Type": "application/json"
                },
                timeout=5  # 5ç§’è¶…æ—¶
            )
            
            if response.status_code == 200:
                data = response.json()
                
                # å°† API è¿”å›çš„æ•°æ®è½¬æ¢ä¸º Document å¯¹è±¡
                docs = []
                for item in data.get("results", []):
                    doc = Document(
                        page_content=item.get("content", ""),
                        metadata={
                            "source": "å¤–éƒ¨API",
                            "type": "external",
                            "api_source": item.get("source", "unknown"),
                            "score": item.get("score", 0.0)
                        }
                    )
                    docs.append(doc)
                
                return docs
            else:
                print(f"   âŒ API è¿”å›é”™è¯¯ï¼š{response.status_code}")
                return []
                
        except requests.Timeout:
            print(f"   âŒ API è¯·æ±‚è¶…æ—¶")
            return []
        except Exception as e:
            print(f"   âŒ API è°ƒç”¨å¤±è´¥ï¼š{e}")
            return []
    
    def _get_max_similarity(self, docs: List[Document]) -> float:
        """è·å–æ–‡æ¡£åˆ—è¡¨ä¸­çš„æœ€é«˜ç›¸ä¼¼åº¦"""
        if not docs:
            return 0.0
        
        # å°è¯•ä»å…ƒæ•°æ®ä¸­è·å–ç›¸ä¼¼åº¦åˆ†æ•°
        scores = []
        for doc in docs:
            score = doc.metadata.get("score", 0.0)
            if score > 0:
                scores.append(score)
        
        if scores:
            return max(scores)
        
        # å¦‚æœæ²¡æœ‰åˆ†æ•°ï¼Œå‡è®¾ç¬¬ä¸€ä¸ªæ–‡æ¡£ç›¸ä¼¼åº¦æœ€é«˜
        # ChromaDB é»˜è®¤æŒ‰ç›¸ä¼¼åº¦æ’åº
        return 0.8  # é»˜è®¤å‡è®¾è¾ƒé«˜ç›¸ä¼¼åº¦
    
    def _merge_results(self, local_docs: List[Document], external_docs: List[Document], k: int) -> List[Document]:
        """åˆå¹¶æœ¬åœ°å’Œå¤–éƒ¨ç»“æœ"""
        # ç®€å•ç­–ç•¥ï¼šæœ¬åœ°ç»“æœä¼˜å…ˆï¼Œç„¶åæ˜¯å¤–éƒ¨ç»“æœ
        merged = local_docs + external_docs
        
        # å»é‡ï¼ˆåŸºäºå†…å®¹ï¼‰
        seen_content = set()
        unique_docs = []
        for doc in merged:
            content_hash = hash(doc.page_content[:100])  # ç”¨å‰100å­—ç¬¦å»é‡
            if content_hash not in seen_content:
                seen_content.add(content_hash)
                unique_docs.append(doc)
        
        # é™åˆ¶è¿”å›æ•°é‡
        return unique_docs[:k]
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "æœ¬åœ°å‘é‡åº“": "å·²å¯ç”¨",
            "å¤–éƒ¨API": "å·²å¯ç”¨" if self.external_api_enabled else "æœªå¯ç”¨",
            "ç›¸ä¼¼åº¦é˜ˆå€¼": self.similarity_threshold,
            "APIåœ°å€": self.external_api_url if self.external_api_enabled else "æœªé…ç½®"
        }


class ExternalAPIAdapter:
    """å¤–éƒ¨ API é€‚é…å™¨ - ç”¨äºä¸åŒ API æ ¼å¼çš„è½¬æ¢"""
    
    @staticmethod
    def adapt_custom_api(response_data: Dict) -> List[Dict]:
        """
        é€‚é…è‡ªå®šä¹‰ API æ ¼å¼
        
        ç¤ºä¾‹è¾“å…¥ï¼š
        {
            "data": [
                {"text": "å†…å®¹1", "source": "æ¥æº1", "relevance": 0.9},
                {"text": "å†…å®¹2", "source": "æ¥æº2", "relevance": 0.8}
            ]
        }
        
        è¾“å‡ºï¼š
        [
            {"content": "å†…å®¹1", "source": "æ¥æº1", "score": 0.9},
            {"content": "å†…å®¹2", "source": "æ¥æº2", "score": 0.8}
        ]
        """
        results = []
        for item in response_data.get("data", []):
            results.append({
                "content": item.get("text", ""),
                "source": item.get("source", "unknown"),
                "score": item.get("relevance", 0.0)
            })
        return results
    
    @staticmethod
    def adapt_elasticsearch(response_data: Dict) -> List[Dict]:
        """é€‚é… Elasticsearch æ ¼å¼"""
        results = []
        hits = response_data.get("hits", {}).get("hits", [])
        for hit in hits:
            results.append({
                "content": hit.get("_source", {}).get("content", ""),
                "source": hit.get("_source", {}).get("source", "unknown"),
                "score": hit.get("_score", 0.0)
            })
        return results
    
    @staticmethod
    def adapt_meilisearch(response_data: Dict) -> List[Dict]:
        """é€‚é… Meilisearch æ ¼å¼"""
        results = []
        for hit in response_data.get("hits", []):
            results.append({
                "content": hit.get("content", ""),
                "source": hit.get("source", "unknown"),
                "score": hit.get("_rankingScore", 0.0)
            })
        return results
