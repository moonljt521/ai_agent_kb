import os
import glob
from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
try:
    from langchain_chroma import Chroma
except ImportError:
    from langchain_community.vectorstores import Chroma
from app.core.embeddings import get_embeddings, get_embedding_info
from dotenv import load_dotenv

load_dotenv()

class RAGManager:
    def __init__(self, data_dir="data", persist_dir="vector_store"):
        self.data_dir = data_dir
        self.persist_dir = persist_dir
        
        # ä½¿ç”¨ç»Ÿä¸€çš„ Embedding è·å–å‡½æ•°ï¼ˆæ”¯æŒå¤šç§æä¾›å•†ï¼‰
        self.embeddings = get_embeddings()
        
        # æ‰“å° Embedding ä¿¡æ¯
        info = get_embedding_info()
        if info.get("is_local"):
            print(f"ğŸ’¡ æç¤ºï¼šä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½")
        
        self.vector_store = None

    def load_and_index(self):
        """åŠ è½½ data ç›®å½•ä¸‹çš„æ–‡æ¡£å¹¶å»ºç«‹ç´¢å¼•"""
        print(f"Loading documents from {self.data_dir}...")
        
        documents = []
        
        # åŠ è½½ PDF
        try:
            pdf_loader = DirectoryLoader(self.data_dir, glob="**/*.pdf", loader_cls=PyPDFLoader)
            pdf_docs = pdf_loader.load()
            documents.extend(pdf_docs)
            if pdf_docs:
                print(f"  âœ… Loaded {len(pdf_docs)} PDF documents")
        except Exception as e:
            print(f"  âš ï¸  Warning loading PDF: {e}")
        
        # åŠ è½½ TXT
        try:
            txt_loader = DirectoryLoader(self.data_dir, glob="**/*.txt", loader_cls=TextLoader)
            txt_docs = txt_loader.load()
            documents.extend(txt_docs)
            if txt_docs:
                print(f"  âœ… Loaded {len(txt_docs)} TXT documents")
        except Exception as e:
            print(f"  âš ï¸  Warning loading TXT: {e}")
        
        # åŠ è½½ MD
        try:
            md_loader = DirectoryLoader(self.data_dir, glob="**/*.md", loader_cls=TextLoader)
            md_docs = md_loader.load()
            documents.extend(md_docs)
            if md_docs:
                print(f"  âœ… Loaded {len(md_docs)} MD documents")
        except Exception as e:
            print(f"  âš ï¸  Warning loading MD: {e}")
        
        # åŠ è½½ EPUBï¼ˆä½¿ç”¨ ebooklibï¼‰
        try:
            import ebooklib
            from ebooklib import epub
            from bs4 import BeautifulSoup
            
            epub_files = glob.glob(os.path.join(self.data_dir, "**/*.epub"), recursive=True)
            epub_count = 0
            
            for epub_file in epub_files:
                try:
                    print(f"  ğŸ“– Processing EPUB: {os.path.basename(epub_file)}")
                    book = epub.read_epub(epub_file)
                    content = []
                    
                    # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
                    for item in book.get_items():
                        if item.get_type() == ebooklib.ITEM_DOCUMENT:
                            soup = BeautifulSoup(item.get_content(), 'html.parser')
                            text = soup.get_text()
                            if text.strip():
                                content.append(text.strip())
                    
                    # åˆå¹¶å†…å®¹å¹¶åˆ›å»ºæ–‡æ¡£
                    if content:
                        full_text = '\n\n'.join(content)
                        doc = Document(
                            page_content=full_text,
                            metadata={"source": epub_file, "format": "epub"}
                        )
                        documents.append(doc)
                        epub_count += 1
                        print(f"  âœ… Loaded EPUB: {os.path.basename(epub_file)} ({len(full_text)} chars)")
                except Exception as e:
                    print(f"  âš ï¸  Error loading {os.path.basename(epub_file)}: {e}")
            
            if epub_count > 0:
                print(f"  âœ… Total EPUB files loaded: {epub_count}")
        except ImportError:
            print(f"  âš ï¸  ebooklib not installed, skipping EPUB files")
        except Exception as e:
            print(f"  âš ï¸  Warning loading EPUB: {e}")
        
        if not documents:
            print("âŒ No documents found.")
            return

        print(f"\nğŸ“š Total documents loaded: {len(documents)}")

        # æ–‡æœ¬åˆ‡ç‰‡
        print(f"âœ‚ï¸  Splitting documents into chunks...")
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        texts = text_splitter.split_documents(documents)
        print(f"âœ‚ï¸  Split into {len(texts)} chunks.")

        # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        print(f"ğŸ”„ Building vector index (this may take a few minutes)...")
        self.vector_store = Chroma.from_documents(
            documents=texts,
            embedding=self.embeddings,
            persist_directory=self.persist_dir
        )
        print("âœ… Indexing completed and persisted.")

    def get_retriever(self):
        """è·å–æ£€ç´¢å™¨"""
        if not self.vector_store:
            # å¦‚æœå†…å­˜é‡Œæ²¡æœ‰ï¼Œå°è¯•ä»æœ¬åœ°åŠ è½½
            self.vector_store = Chroma(
                persist_directory=self.persist_dir,
                embedding_function=self.embeddings
            )
        return self.vector_store.as_retriever(search_kwargs={"k": 3})
