"""
Embedding æ¨¡å‹ç®¡ç†æ¨¡å—
æ”¯æŒå¤šç§ Embedding æä¾›å•†ï¼šé˜¿é‡Œäº‘ã€BGEã€M3Eã€Text2Vecã€OpenAI
"""

import os
from dotenv import load_dotenv

load_dotenv()

def get_embeddings():
    """
    æ ¹æ®ç¯å¢ƒå˜é‡è¿”å›ç›¸åº”çš„ Embedding æ¨¡å‹
    
    æ”¯æŒçš„æä¾›å•†ï¼š
    - aliyun: é˜¿é‡Œäº‘ DashScope (ä»˜è´¹ï¼Œæ€§èƒ½æœ€å¼º)
    - bge: BGE ç³»åˆ—æœ¬åœ°æ¨¡å‹ (å…è´¹ï¼Œæ¨è)
    - m3e: M3E æœ¬åœ°æ¨¡å‹ (å…è´¹)
    - text2vec: Text2Vec æœ¬åœ°æ¨¡å‹ (å…è´¹)
    - openai: OpenAI (ä»˜è´¹)
    
    ç¯å¢ƒå˜é‡é…ç½®ï¼š
    EMBEDDING_PROVIDER=bge  # æä¾›å•†é€‰æ‹©
    BGE_MODEL=BAAI/bge-large-zh-v1.5  # BGE æ¨¡å‹é€‰æ‹©
    DEVICE=cpu  # è®¾å¤‡é€‰æ‹© (cpu æˆ– cuda)
    """
    provider = os.getenv("EMBEDDING_PROVIDER", "bge").lower()
    
    print(f"\n{'='*60}")
    print(f"ğŸ”§ åˆå§‹åŒ– Embedding æ¨¡å‹")
    print(f"{'='*60}")
    print(f"ğŸ“¦ æä¾›å•†: {provider}")
    
    if provider == "aliyun":
        from langchain_community.embeddings import DashScopeEmbeddings
        model = os.getenv("EMBEDDING_MODEL", "text-embedding-v3")
        print(f"âœ… ä½¿ç”¨é˜¿é‡Œäº‘æ¨¡å‹: {model}")
        print(f"ğŸ“Š ç»´åº¦: 1536")
        print(f"ğŸ’° è´¹ç”¨: Â¥0.0007/åƒtokens")
        print(f"ğŸŒ éœ€è¦ç½‘ç»œè¿æ¥")
        print(f"{'='*60}\n")
        return DashScopeEmbeddings(model=model)
    
    elif provider == "bge":
        from langchain_community.embeddings import HuggingFaceEmbeddings
        model_name = os.getenv("BGE_MODEL", "BAAI/bge-large-zh-v1.5")
        device = os.getenv("DEVICE", "cpu")
        
        # æ ¹æ®æ¨¡å‹åç§°ç¡®å®šç»´åº¦
        if "large" in model_name:
            dimension = 1024
            size = "1.3GB"
        elif "base" in model_name:
            dimension = 768
            size = "400MB"
        elif "small" in model_name:
            dimension = 512
            size = "100MB"
        else:
            dimension = "æœªçŸ¥"
            size = "æœªçŸ¥"
        
        print(f"âœ… ä½¿ç”¨ BGE æ¨¡å‹: {model_name}")
        print(f"ğŸ“Š ç»´åº¦: {dimension}")
        print(f"ğŸ’¾ å¤§å°: {size}")
        print(f"ğŸ–¥ï¸  è®¾å¤‡: {device.upper()}")
        print(f"ğŸ’° è´¹ç”¨: å®Œå…¨å…è´¹")
        print(f"ğŸ“¡ æœ¬åœ°è¿è¡Œï¼Œæ— éœ€ç½‘ç»œ")
        print(f"â³ é¦–æ¬¡ä½¿ç”¨ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹åˆ° ~/.cache/huggingface/")
        print(f"{'='*60}\n")
        
        return HuggingFaceEmbeddings(
            model_name=model_name,
            model_kwargs={'device': device},
            encode_kwargs={'normalize_embeddings': True}
        )
    
    elif provider == "m3e":
        from langchain_community.embeddings import HuggingFaceEmbeddings
        device = os.getenv("DEVICE", "cpu")
        
        print(f"âœ… ä½¿ç”¨ M3E æ¨¡å‹: moka-ai/m3e-base")
        print(f"ğŸ“Š ç»´åº¦: 768")
        print(f"ğŸ’¾ å¤§å°: 400MB")
        print(f"ğŸ–¥ï¸  è®¾å¤‡: {device.upper()}")
        print(f"ğŸ’° è´¹ç”¨: å®Œå…¨å…è´¹")
        print(f"ğŸ“¡ æœ¬åœ°è¿è¡Œï¼Œæ— éœ€ç½‘ç»œ")
        print(f"{'='*60}\n")
        
        return HuggingFaceEmbeddings(
            model_name="moka-ai/m3e-base",
            model_kwargs={'device': device},
            encode_kwargs={'normalize_embeddings': True}
        )
    
    elif provider == "text2vec":
        from langchain_community.embeddings import HuggingFaceEmbeddings
        device = os.getenv("DEVICE", "cpu")
        
        print(f"âœ… ä½¿ç”¨ Text2Vec æ¨¡å‹: shibing624/text2vec-base-chinese")
        print(f"ğŸ“Š ç»´åº¦: 768")
        print(f"ğŸ’¾ å¤§å°: 400MB")
        print(f"ğŸ–¥ï¸  è®¾å¤‡: {device.upper()}")
        print(f"ğŸ’° è´¹ç”¨: å®Œå…¨å…è´¹")
        print(f"ğŸ“¡ æœ¬åœ°è¿è¡Œï¼Œæ— éœ€ç½‘ç»œ")
        print(f"{'='*60}\n")
        
        return HuggingFaceEmbeddings(
            model_name="shibing624/text2vec-base-chinese",
            model_kwargs={'device': device},
            encode_kwargs={'normalize_embeddings': True}
        )
    
    elif provider == "openai":
        from langchain_openai import OpenAIEmbeddings
        model = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-small")
        
        print(f"âœ… ä½¿ç”¨ OpenAI æ¨¡å‹: {model}")
        print(f"ğŸ“Š ç»´åº¦: 1536 (small) æˆ– 3072 (large)")
        print(f"ğŸ’° è´¹ç”¨: $0.00002/åƒtokens (small)")
        print(f"ğŸŒ éœ€è¦ç½‘ç»œè¿æ¥")
        print(f"{'='*60}\n")
        
        return OpenAIEmbeddings(model=model)
    
    else:
        raise ValueError(
            f"\nâŒ æœªçŸ¥çš„ Embedding æä¾›å•†: {provider}\n"
            f"æ”¯æŒçš„æä¾›å•†: aliyun, bge, m3e, text2vec, openai\n"
            f"è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® EMBEDDING_PROVIDER"
        )

def get_embedding_info():
    """è·å–å½“å‰ Embedding æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯"""
    provider = os.getenv("EMBEDDING_PROVIDER", "bge").lower()
    
    info = {
        "provider": provider,
        "is_local": provider in ["bge", "m3e", "text2vec"],
        "is_free": provider in ["bge", "m3e", "text2vec"],
    }
    
    if provider == "aliyun":
        info["model"] = os.getenv("EMBEDDING_MODEL", "text-embedding-v3")
        info["dimension"] = 1536
        info["cost_per_1k_tokens"] = 0.0007
        info["requires_network"] = True
    
    elif provider == "bge":
        model_name = os.getenv("BGE_MODEL", "BAAI/bge-large-zh-v1.5")
        info["model"] = model_name
        info["requires_network"] = False
        
        if "large" in model_name:
            info["dimension"] = 1024
            info["size"] = "1.3GB"
            info["performance"] = "æœ€å¼º"
        elif "base" in model_name:
            info["dimension"] = 768
            info["size"] = "400MB"
            info["performance"] = "ä¼˜ç§€"
        elif "small" in model_name:
            info["dimension"] = 512
            info["size"] = "100MB"
            info["performance"] = "è‰¯å¥½"
    
    elif provider == "m3e":
        info["model"] = "moka-ai/m3e-base"
        info["dimension"] = 768
        info["size"] = "400MB"
        info["requires_network"] = False
    
    elif provider == "text2vec":
        info["model"] = "shibing624/text2vec-base-chinese"
        info["dimension"] = 768
        info["size"] = "400MB"
        info["requires_network"] = False
    
    elif provider == "openai":
        model = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-small")
        info["model"] = model
        info["dimension"] = 1536 if "small" in model else 3072
        info["cost_per_1k_tokens"] = 0.00002
        info["requires_network"] = True
    
    return info

def print_embedding_comparison():
    """æ‰“å° Embedding æ¨¡å‹å¯¹æ¯”è¡¨"""
    print("\n" + "="*80)
    print("ğŸ“Š Embedding æ¨¡å‹å¯¹æ¯”")
    print("="*80)
    print(f"{'æ¨¡å‹':<30} {'ç»´åº¦':<8} {'å¤§å°':<10} {'è´¹ç”¨':<15} {'æ€§èƒ½':<10}")
    print("-"*80)
    print(f"{'é˜¿é‡Œäº‘ text-embedding-v3':<30} {'1536':<8} {'API':<10} {'Â¥0.0007/åƒtokens':<15} {'â­â­â­â­â­':<10}")
    print(f"{'BGE-large-zh-v1.5':<30} {'1024':<8} {'1.3GB':<10} {'å…è´¹':<15} {'â­â­â­â­â­':<10}")
    print(f"{'BGE-base-zh-v1.5':<30} {'768':<8} {'400MB':<10} {'å…è´¹':<15} {'â­â­â­â­':<10}")
    print(f"{'BGE-small-zh-v1.5':<30} {'512':<8} {'100MB':<10} {'å…è´¹':<15} {'â­â­â­':<10}")
    print(f"{'M3E-base':<30} {'768':<8} {'400MB':<10} {'å…è´¹':<15} {'â­â­â­â­':<10}")
    print(f"{'Text2Vec-base':<30} {'768':<8} {'400MB':<10} {'å…è´¹':<15} {'â­â­â­':<10}")
    print("="*80)
    print("\nğŸ’¡ æ¨èï¼šBGE-large-zh-v1.5 (å…è´¹ + é«˜æ€§èƒ½)")
    print("ğŸ’¡ è½»é‡ï¼šBGE-small-zh-v1.5 (å¿«é€Ÿ + ä½å†…å­˜)")
    print("ğŸ’¡ æœ€å¼ºï¼šé˜¿é‡Œäº‘ text-embedding-v3 (ä»˜è´¹ + æœ€ä½³æ€§èƒ½)\n")

# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print_embedding_comparison()
    
    print("\næµ‹è¯•å½“å‰é…ç½®ï¼š")
    embeddings = get_embeddings()
    
    print("\næµ‹è¯•å‘é‡åŒ–ï¼š")
    text = "è´¾å®ç‰æ˜¯çº¢æ¥¼æ¢¦çš„ä¸»è§’"
    vector = embeddings.embed_query(text)
    print(f"æ–‡æœ¬: {text}")
    print(f"å‘é‡ç»´åº¦: {len(vector)}")
    print(f"å‘é‡å‰5ä¸ªå€¼: {vector[:5]}")
    
    info = get_embedding_info()
    print(f"\næ¨¡å‹ä¿¡æ¯: {info}")
