"""
çº¯ LLM å¯¹è¯è„šæœ¬ - ä¸ä½¿ç”¨çŸ¥è¯†åº“ï¼Œå®Œå…¨å…è´¹
é€‚åˆï¼š
- è°ƒè¯• LLM
- é€šç”¨å¯¹è¯
- ä¸éœ€è¦çŸ¥è¯†åº“çš„åœºæ™¯
"""
import sys
import os
sys.path.append(os.getcwd())

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from dotenv import load_dotenv

load_dotenv()

def get_llm():
    """è·å– LLM å®ä¾‹"""
    provider = os.getenv("MODEL_PROVIDER", "aliyun").lower()
    
    if provider == "groq":
        llm = ChatOpenAI(
            model=os.getenv("GROQ_LLM_MODEL", "llama-3.3-70b-versatile"),
            openai_api_base="https://api.groq.com/openai/v1",
            openai_api_key=os.getenv("GROQ_API_KEY")
        )
        print(f"âœ… ä½¿ç”¨ Groq æ¨¡å‹: {os.getenv('GROQ_LLM_MODEL', 'llama-3.3-70b-versatile')}")
        print("ğŸ’° å®Œå…¨å…è´¹æ¨¡å¼ï¼ˆä¸ä½¿ç”¨çŸ¥è¯†åº“ï¼‰")
    else:
        llm = ChatOpenAI(
            model=os.getenv("LLM_MODEL", "qwen-plus"),
            openai_api_base="https://dashscope.aliyuncs.com/compatible-mode/v1",
            openai_api_key=os.getenv("DASHSCOPE_API_KEY")
        )
        print(f"âœ… ä½¿ç”¨é˜¿é‡Œäº‘æ¨¡å‹: {os.getenv('LLM_MODEL', 'qwen-plus')}")
        print("ğŸ’° æŒ‰ Token è®¡è´¹ï¼ˆä¸ä½¿ç”¨çŸ¥è¯†åº“ï¼‰")
    
    return llm

def print_separator():
    print("\n" + "=" * 70 + "\n")

def single_question_mode(llm, query):
    """å•æ¬¡æé—®æ¨¡å¼"""
    print("=" * 70)
    print("ğŸ¤– çº¯ LLM å¯¹è¯ï¼ˆæ— çŸ¥è¯†åº“ï¼‰")
    print("=" * 70)
    print(f"\nğŸ’¬ é—®é¢˜ï¼š{query}\n")
    print("â³ æ­£åœ¨æ€è€ƒ...\n")
    
    try:
        messages = [HumanMessage(content=query)]
        response = llm.invoke(messages)
        
        print("ğŸ¤– å›ç­”ï¼š")
        print("-" * 70)
        print(response.content)
        print("-" * 70)
        print("\nğŸ“Š æ•°æ®æ¥æºï¼šâŒ çº¯ LLMï¼ˆæœªä½¿ç”¨çŸ¥è¯†åº“ï¼‰")
        print("\n" + "=" * 70)
        
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼š{e}")
        sys.exit(1)

def interactive_mode(llm):
    """äº¤äº’å¼å¯¹è¯æ¨¡å¼"""
    print("=" * 70)
    print("ğŸ¤– çº¯ LLM å¯¹è¯ï¼ˆæ— çŸ¥è¯†åº“ï¼‰")
    print("=" * 70)
    print("\nğŸ’¡ æç¤ºï¼š")
    print("  - ç›´æ¥è¾“å…¥é—®é¢˜ï¼ŒæŒ‰å›è½¦è·å¾—ç­”æ¡ˆ")
    print("  - è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º")
    print("  - è¾“å…¥ 'clear' æ¸…å±")
    print("  - ä¸ä½¿ç”¨çŸ¥è¯†åº“ï¼Œå®Œå…¨å…è´¹ï¼ˆGroqï¼‰")
    print_separator()
    
    # å¯¹è¯å†å²
    conversation_history = []
    
    while True:
        try:
            query = input("ğŸ’¬ ä½ çš„é—®é¢˜ï¼š").strip()
            
            if not query:
                continue
            
            if query.lower() in ['exit', 'quit', 'q']:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            
            if query.lower() == 'clear':
                os.system('clear' if os.name != 'nt' else 'cls')
                conversation_history = []
                print("ğŸ—‘ï¸  å¯¹è¯å†å²å·²æ¸…ç©º")
                continue
            
            if query.lower() == 'history':
                print("\nğŸ“œ å¯¹è¯å†å²ï¼š")
                for i, msg in enumerate(conversation_history, 1):
                    role = "ğŸ‘¤" if msg.type == "human" else "ğŸ¤–"
                    print(f"{role} {i}: {msg.content[:100]}...")
                continue
            
            print("\nâ³ æ­£åœ¨æ€è€ƒ...\n")
            
            try:
                # æ„å»ºæ¶ˆæ¯ï¼ˆåŒ…å«å†å²ï¼‰
                messages = conversation_history + [HumanMessage(content=query)]
                response = llm.invoke(messages)
                
                # ä¿å­˜åˆ°å†å²
                conversation_history.append(HumanMessage(content=query))
                conversation_history.append(response)
                
                # é™åˆ¶å†å²é•¿åº¦ï¼ˆæœ€å¤šä¿ç•™ 10 è½®å¯¹è¯ï¼‰
                if len(conversation_history) > 20:
                    conversation_history = conversation_history[-20:]
                
                print("ğŸ¤– å›ç­”ï¼š")
                print("-" * 70)
                print(response.content)
                print("-" * 70)
                print("\nğŸ“Š æ•°æ®æ¥æºï¼šâŒ çº¯ LLMï¼ˆæœªä½¿ç”¨çŸ¥è¯†åº“ï¼‰")
                
            except Exception as e:
                print(f"âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™ï¼š{e}")
            
            print_separator()
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except EOFError:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break

def main():
    llm = get_llm()
    print()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        # å•æ¬¡æé—®æ¨¡å¼
        query = " ".join(sys.argv[1:])
        single_question_mode(llm, query)
    else:
        # äº¤äº’å¼æ¨¡å¼
        interactive_mode(llm)

if __name__ == "__main__":
    main()
