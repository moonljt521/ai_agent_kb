"""
èŠå¤©è„šæœ¬ - æ”¯æŒäº¤äº’å¼å’Œå•æ¬¡æé—®ä¸¤ç§æ¨¡å¼
æ”¯æŒ --no-rag å‚æ•°ï¼Œä¸ä½¿ç”¨çŸ¥è¯†åº“ï¼ˆå®Œå…¨å…è´¹ï¼‰
"""
import sys
import os
sys.path.append(os.getcwd())

from app.core.agent import AgentManager
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from dotenv import load_dotenv

load_dotenv()

# æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ --no-rag æ¨¡å¼
USE_RAG = "--no-rag" not in sys.argv
if not USE_RAG:
    sys.argv.remove("--no-rag")

def get_llm():
    """è·å–çº¯ LLM å®ä¾‹ï¼ˆä¸ä½¿ç”¨ RAGï¼‰"""
    provider = os.getenv("MODEL_PROVIDER", "aliyun").lower()
    
    if provider == "groq":
        llm = ChatOpenAI(
            model=os.getenv("GROQ_LLM_MODEL", "llama-3.3-70b-versatile"),
            openai_api_base="https://api.groq.com/openai/v1",
            openai_api_key=os.getenv("GROQ_API_KEY")
        )
        print(f"âœ… ä½¿ç”¨ Groq æ¨¡å‹: {os.getenv('GROQ_LLM_MODEL', 'llama-3.3-70b-versatile')}")
        print("ğŸ’° å®Œå…¨å…è´¹æ¨¡å¼ï¼ˆä¸ä½¿ç”¨çŸ¥è¯†åº“ï¼‰")
    else:
        llm = ChatOpenAI(
            model=os.getenv("LLM_MODEL", "qwen-plus"),
            openai_api_base="https://dashscope.aliyuncs.com/compatible-mode/v1",
            openai_api_key=os.getenv("DASHSCOPE_API_KEY")
        )
        print(f"âœ… ä½¿ç”¨é˜¿é‡Œäº‘æ¨¡å‹: {os.getenv('LLM_MODEL', 'qwen-plus')}")
        print("ğŸ’° æŒ‰ Token è®¡è´¹ï¼ˆä¸ä½¿ç”¨çŸ¥è¯†åº“ï¼‰")
    
    return llm

def print_separator():
    print("\n" + "=" * 70 + "\n")

def print_source_info(retrieval_info):
    """æ‰“å°æ•°æ®æ¥æºä¿¡æ¯"""
    if retrieval_info['used_knowledge_base']:
        print(f"ğŸ“Š æ•°æ®æ¥æºï¼šâœ… æœ¬åœ°çŸ¥è¯†åº“")
        print(f"ğŸ“„ æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡ï¼š{retrieval_info['retrieved_docs_count']}")
        
        if retrieval_info['sources']:
            print(f"\nğŸ“š å¼•ç”¨çš„æ–‡æ¡£ï¼š")
            for i, source in enumerate(retrieval_info['sources'], 1):
                print(f"  [{i}] {source['source']} (é¡µç : {source['page']})")
    else:
        print(f"ğŸ“Š æ•°æ®æ¥æºï¼šâŒ æ¨¡å‹é€šç”¨çŸ¥è¯†")

def single_question_mode(query):
    """å•æ¬¡æé—®æ¨¡å¼"""
    print("=" * 70)
    print(f"ğŸ¤– AI Agent çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ {'ï¼ˆçº¯ LLM æ¨¡å¼ï¼‰' if not USE_RAG else ''}")
    print("=" * 70)
    print(f"\nğŸ’¬ é—®é¢˜ï¼š{query}\n")
    print("â³ æ­£åœ¨æ€è€ƒ...\n")
    
    try:
        if USE_RAG:
            agent = AgentManager()
            answer = agent.run(query)
            retrieval_info = agent.get_last_retrieval_info()
            
            print("ğŸ¤– å›ç­”ï¼š")
            print("-" * 70)
            print(answer)
            print("-" * 70)
            print()
            print_source_info(retrieval_info)
        else:
            llm = get_llm()
            messages = [HumanMessage(content=query)]
            response = llm.invoke(messages)
            
            print("ğŸ¤– å›ç­”ï¼š")
            print("-" * 70)
            print(response.content)
            print("-" * 70)
            print("\nğŸ“Š æ•°æ®æ¥æºï¼šâŒ çº¯ LLMï¼ˆæœªä½¿ç”¨çŸ¥è¯†åº“ï¼‰")
        
        print("\n" + "=" * 70)
        
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼š{e}")
        sys.exit(1)

def interactive_mode():
    """äº¤äº’å¼èŠå¤©æ¨¡å¼"""
    print("=" * 70)
    print(f"ğŸ¤– AI Agent çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ {'ï¼ˆçº¯ LLM æ¨¡å¼ï¼‰' if not USE_RAG else ''}")
    print("=" * 70)
    print("\nğŸ’¡ æç¤ºï¼š")
    print("  - ç›´æ¥è¾“å…¥é—®é¢˜ï¼ŒæŒ‰å›è½¦è·å¾—ç­”æ¡ˆ")
    print("  - è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º")
    print("  - è¾“å…¥ 'clear' æ¸…å±")
    if not USE_RAG:
        print("  - ğŸ’° ä¸ä½¿ç”¨çŸ¥è¯†åº“ï¼Œå®Œå…¨å…è´¹ï¼ˆGroqï¼‰")
    print_separator()
    
    if USE_RAG:
        print("â³ æ­£åœ¨åˆå§‹åŒ–...")
        try:
            agent = AgentManager()
            print("âœ… åˆå§‹åŒ–æˆåŠŸï¼\n")
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥ï¼š{e}")
            print("\nğŸ’¡ è¯·ç¡®ä¿å·²è¿è¡Œ 'python scripts/ingest.py' å¯¼å…¥æ–‡æ¡£")
            return
        
        conversation_history = None
    else:
        llm = get_llm()
        print()
        conversation_history = []
    
    while True:
        try:
            query = input("ğŸ’¬ ä½ çš„é—®é¢˜ï¼š").strip()
            
            if not query:
                continue
            
            if query.lower() in ['exit', 'quit', 'q']:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            
            if query.lower() == 'clear':
                os.system('clear' if os.name != 'nt' else 'cls')
                if not USE_RAG:
                    conversation_history = []
                    print("ğŸ—‘ï¸  å¯¹è¯å†å²å·²æ¸…ç©º")
                continue
            
            print("\nâ³ æ­£åœ¨æ€è€ƒ...\n")
            
            try:
                if USE_RAG:
                    answer = agent.run(query)
                    retrieval_info = agent.get_last_retrieval_info()
                    
                    print("ğŸ¤– å›ç­”ï¼š")
                    print("-" * 70)
                    print(answer)
                    print("-" * 70)
                    print()
                    print_source_info(retrieval_info)
                else:
                    # çº¯ LLM æ¨¡å¼ï¼ˆå¸¦å¯¹è¯å†å²ï¼‰
                    messages = conversation_history + [HumanMessage(content=query)]
                    response = llm.invoke(messages)
                    
                    # ä¿å­˜åˆ°å†å²
                    conversation_history.append(HumanMessage(content=query))
                    conversation_history.append(response)
                    
                    # é™åˆ¶å†å²é•¿åº¦
                    if len(conversation_history) > 20:
                        conversation_history = conversation_history[-20:]
                    
                    print("ğŸ¤– å›ç­”ï¼š")
                    print("-" * 70)
                    print(response.content)
                    print("-" * 70)
                    print("\nğŸ“Š æ•°æ®æ¥æºï¼šâŒ çº¯ LLMï¼ˆæœªä½¿ç”¨çŸ¥è¯†åº“ï¼‰")
                
            except Exception as e:
                print(f"âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™ï¼š{e}")
            
            print_separator()
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except EOFError:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break

def main():
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        # å•æ¬¡æé—®æ¨¡å¼
        query = " ".join(sys.argv[1:])
        single_question_mode(query)
    else:
        # äº¤äº’å¼æ¨¡å¼
        interactive_mode()

if __name__ == "__main__":
    main()
