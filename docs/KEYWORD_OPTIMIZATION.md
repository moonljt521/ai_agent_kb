# 关键词优化 - 直接检索模式

## 优化目标

减少 LLM 调用，降低成本，提升响应速度。

## 优化原理

### 优化前流程
```
用户提问 → LLM 决策 → 检索向量库 → LLM 生成答案
费用：Embedding + LLM × 2
时间：4-5 秒
```

### 优化后流程
```
用户提问 → 关键词匹配？
            ├─ 命中 → 直接检索向量库 → 返回原文
            │         费用：Embedding
            │         时间：0.5 秒 ⚡
            │
            └─ 未命中 → 走原流程（LLM）
                       费用：Embedding + LLM × 2
                       时间：4-5 秒
```

## 关键词配置

配置文件：`config/keywords.json`

### 已配置关键词（341个）

#### 四大名著人物（184个）
- **红楼梦**：贾宝玉、林黛玉、薛宝钗、王熙凤...（46个）
- **三国演义**：刘备、关羽、张飞、诸葛亮、曹操...（55个）
- **西游记**：孙悟空、唐僧、猪八戒、沙僧...（35个）
- **水浒传**：宋江、林冲、武松、鲁智深...（48个）

#### 地点（58个）
- 大观园、荣国府、赤壁、花果山、梁山泊...

#### 事件（33个）
- 三顾茅庐、火烧赤壁、大闹天宫、武松打虎...

#### 物品（24个）
- 通灵宝玉、金箍棒、青龙偃月刀、芭蕉扇...

#### 通用词条（21个）
- 是谁、什么人、故事、经历、性格、关系...

## 匹配规则

### 命中条件
问题中包含**任意一个**关键词即命中。

### 示例

✅ **命中（直接检索）**
```
"贾宝玉是谁？"           → 命中：贾宝玉、是谁
"诸葛亮的故事"           → 命中：诸葛亮、故事
"孙悟空的师傅是谁"       → 命中：孙悟空、师傅、是谁
"武松打虎的经历"         → 命中：武松、武松打虎、经历
"林黛玉和薛宝钗的关系"   → 命中：林黛玉、薛宝钗、关系
```

❌ **未命中（使用 LLM）**
```
"今天天气怎么样"         → 未命中任何关键词
"什么是人工智能"         → 未命中任何关键词
"如何学习编程"           → 未命中任何关键词
```

## 直接检索返回格式

直接检索会返回向量库中最相关的 3 个文档片段：

```
【片段 1】（来源：红楼梦.epub，页码：12）
贾宝玉，别号怡红公子，荣国府衔玉而诞的公子...

【片段 2】（来源：红楼梦.epub，页码：45）
宝玉生于荣国府，自幼深得贾母疼爱...

【片段 3】（来源：红楼梦.epub，页码：78）
宝玉与黛玉青梅竹马，情投意合...
```

## 性能对比

### 响应时间

| 模式 | 时间 | 说明 |
|------|------|------|
| 直接检索 | 0.5s | ⚡⚡⚡ 最快 |
| Groq + RAG | 1-2s | ⚡⚡ 很快 |
| 阿里云 + Agent | 4-5s | ⚡ 正常 |

### 费用对比（单次提问）

| 模式 | Embedding | LLM | 总计 |
|------|-----------|-----|------|
| 直接检索 | ¥0.00001 | ¥0 | **¥0.00001** ⚡ |
| Groq + RAG | ¥0.00001 | ¥0 | ¥0.00001 |
| 阿里云 + Agent | ¥0.00001 | ¥0.015 | ¥0.015 |

**直接检索比 Agent 模式便宜 1500 倍！**

### 100 次提问费用对比

假设 70% 命中关键词（直接检索），30% 使用 LLM：

| 模式 | 费用 | 说明 |
|------|------|------|
| 优化前（全部 Agent） | ¥1.50 | 100 次 × ¥0.015 |
| 优化后（70% 直接） | ¥0.45 | 70 × ¥0.00001 + 30 × ¥0.015 |
| **节省** | **¥1.05** | **节省 70%** 🎉 |

## 使用方法

### 自动启用
优化功能已自动集成，无需额外配置。

### 测试

```bash
# 启动服务
bash start_web.sh

# 测试命中关键词（直接检索）
curl "http://127.0.0.1:8000/chat?query=贾宝玉是谁"

# 测试未命中（使用 LLM）
curl "http://127.0.0.1:8000/chat?query=今天天气怎么样"
```

### 查看日志

启动服务时会显示：
```
✅ 使用阿里云模型: qwen-plus
📚 已加载 341 个关键词
💡 命中关键词将直接检索，节省 LLM 调用
```

提问时会显示：
```
🎯 ✅ 命中关键词: 贾宝玉, 是谁，直接检索向量库
```
或
```
🤖 ❌ 未命中任何关键词，使用 LLM 处理
```

## 自定义关键词

### 添加关键词

编辑 `config/keywords.json`：

```json
{
  "四大名著": {
    "红楼梦": {
      "人物": [
        "贾宝玉",
        "林黛玉",
        "你的新人物"  // 添加这里
      ]
    }
  },
  "通用词条": [
    "是谁",
    "故事",
    "你的新词条"  // 或添加这里
  ]
}
```

### 重启服务

```bash
# 重启后自动加载新关键词
bash start_web.sh
```

## 适用场景

### ✅ 适合直接检索
- 查询具体人物、地点、事件
- 简单的事实性问题
- 关键词明确的问题

### ❌ 不适合直接检索
- 需要推理、分析的问题
- 需要对比、总结的问题
- 开放性问题
- 与知识库无关的问题

## 优缺点

### 优点
- ⚡ **速度快**：0.5秒响应
- 💰 **成本低**：节省 70% 费用
- 🎯 **准确**：直接返回原文，无 LLM 幻觉
- 📚 **可控**：可自定义关键词

### 缺点
- 📝 **格式简单**：直接返回原文，无 LLM 润色
- 🔍 **需要命中**：未命中关键词仍走 LLM
- 🛠️ **需维护**：关键词需要手动配置

## 未来优化

### 1. 智能关键词提取
自动从文档中提取关键词，无需手动配置。

### 2. 模糊匹配
支持拼音、同义词、错别字匹配。

### 3. 智能路由
根据问题复杂度自动选择直接检索或 LLM。

### 4. 缓存机制
缓存常见问题的答案，进一步提升速度。

## 监控统计

### 查看关键词统计

```bash
venv/bin/python app/core/keyword_matcher.py
```

输出：
```json
{
  "总关键词数": 341,
  "四大名著": {
    "红楼梦": {
      "总数": 68,
      "分类": {
        "人物": 46,
        "地点": 12,
        "物品": 6,
        "诗词": 4
      }
    },
    ...
  }
}
```

### API 返回信息

```json
{
  "query": "贾宝玉是谁",
  "answer": "【片段 1】...",
  "knowledge_base_used": true,
  "used_direct_retrieval": true,  // 是否使用直接检索
  "retrieved_docs_count": 3,
  "data_source": "本地知识库（直接检索）"
}
```

## 总结

关键词优化通过智能路由，在保证准确性的前提下：
- ⚡ 提升 8 倍响应速度
- 💰 节省 70% 费用
- 🎯 减少 LLM 幻觉

对于四大名著这类有明确关键词的知识库，优化效果显著！
