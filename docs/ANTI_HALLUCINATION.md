# 防止 AI 幻觉的策略

## 什么是 AI 幻觉？

AI 幻觉（Hallucination）是指大语言模型生成看似合理但实际上不准确或虚构的内容。在知识问答系统中，这可能导致：
- 编造不存在的事实
- 混淆不同来源的信息
- 过度推理超出原文范围
- 给出错误的引用

## 我们的防护策略

### 1. 提示词工程（Prompt Engineering）
**核心原则**：明确指示 LLM 只基于提供的上下文回答

**优化前**：
```
请基于以下知识库内容回答用户的问题。
```

**优化后**：
```
你是一个严谨的知识问答助手。请严格遵守以下规则：

1. 只能基于提供的知识库内容回答问题
2. 如果知识库内容不足以回答问题，明确说明"知识库中没有相关信息"
3. 不要编造、推测或使用知识库外的信息
4. 引用原文时要准确，不要篡改原意
5. 如果问题模糊，要求用户澄清
```

### 2. 相似度阈值过滤
**目的**：过滤掉相似度过低的检索结果

```python
# 设置相似度阈值（0-1之间，越高越严格）
SIMILARITY_THRESHOLD = 0.7

# 只保留高相似度的文档
filtered_docs = [doc for doc in docs if doc.metadata.get('score', 0) > SIMILARITY_THRESHOLD]
```

### 3. 答案置信度评估
**方法**：让 LLM 自我评估答案的可信度

```python
# 在生成答案后，要求 LLM 评估置信度
confidence_prompt = """
基于你刚才的回答，请评估：
1. 答案的置信度（高/中/低）
2. 是否完全基于提供的知识库内容
3. 是否有任何推测或不确定的部分
"""
```

### 4. 引用验证
**方法**：要求 LLM 在答案中标注引用来源

```python
# 提示词中要求标注引用
prompt = """
请在回答中标注信息来源，格式如：[来源：文档名]
如果某个信息无法在知识库中找到依据，不要回答该部分。
"""
```

### 5. 多轮验证
**方法**：对关键问题进行二次验证

```python
# 第一轮：生成答案
answer = llm.invoke(prompt)

# 第二轮：验证答案
verification_prompt = f"""
原始问题：{query}
生成的答案：{answer}
知识库内容：{context}

请验证答案是否完全基于知识库内容，是否有任何虚构或推测的部分。
"""
```

### 6. 黑名单关键词检测
**方法**：检测答案中的不确定性词汇

```python
UNCERTAINTY_KEYWORDS = [
    "可能", "也许", "大概", "据说", "传说",
    "我认为", "我觉得", "应该是", "估计"
]

# 如果答案包含过多不确定词汇，降低置信度或警告用户
```

### 7. 知识库覆盖率检查
**方法**：检查问题是否在知识库覆盖范围内

```python
# 检查检索到的文档数量和相似度
if len(docs) == 0:
    return "抱歉，知识库中没有相关信息。"
elif max_similarity < 0.5:
    return "知识库中可能没有足够的信息来回答这个问题。"
```

## 实施优先级

### 高优先级（立即实施）
1. ✅ 优化提示词 - 明确约束 LLM 行为
2. ✅ 相似度阈值过滤 - 过滤低质量检索结果
3. ✅ 知识库覆盖率检查 - 及时告知用户信息不足

### 中优先级（建议实施）
4. 引用验证 - 要求标注来源
5. 答案置信度评估 - 自动评估可信度

### 低优先级（可选）
6. 多轮验证 - 增加成本但提高准确性
7. 黑名单关键词检测 - 辅助判断

## 效果评估

### 评估指标
- **准确率**：答案与原文的一致性
- **拒答率**：对无法回答的问题说"不知道"的比例
- **幻觉率**：生成虚假信息的比例
- **用户满意度**：用户反馈

### 监控方法
```python
# 记录每次问答的元数据
{
    "query": "问题",
    "retrieved_docs_count": 3,
    "max_similarity": 0.85,
    "answer_length": 500,
    "confidence": "high",
    "has_uncertainty_keywords": false
}
```

## 最佳实践

1. **宁可拒答，不要乱答**：当信息不足时，明确告知用户
2. **保持透明**：让用户知道答案的来源和可信度
3. **持续优化**：根据用户反馈调整策略
4. **人工审核**：对关键领域的答案进行人工复核

## 参考资料

- [RAG 系统中的幻觉问题](https://arxiv.org/abs/2311.08401)
- [提示词工程最佳实践](https://platform.openai.com/docs/guides/prompt-engineering)
- [检索增强生成的评估方法](https://arxiv.org/abs/2309.01431)
