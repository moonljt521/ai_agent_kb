# 大模型优化策略详解

## 核心概念速览

| 策略 | 难度 | 成本 | 效果 | 你的项目 |
|------|------|------|------|----------|
| Prompt Engineering | ⭐ | 免费 | ⭐⭐⭐ | 可优化 |
| Few-Shot | ⭐⭐ | 免费 | ⭐⭐⭐⭐ | 可添加 |
| CoT（思维链） | ⭐⭐ | 免费 | ⭐⭐⭐⭐ | 可添加 |
| RAG | ⭐⭐⭐ | 低 | ⭐⭐⭐⭐⭐ | ✅ 已实现 |
| Fine-tuning | ⭐⭐⭐⭐⭐ | 高 | ⭐⭐⭐⭐⭐ | 不需要 |

---

## 1. Few-Shot Learning（少样本学习）

### 什么是 Few-Shot？

通过给模型展示几个**示例**，让它学会你想要的回答风格和格式。

### 三种模式

#### Zero-Shot（零样本）- 不给示例
```
问题：贾宝玉是谁？
```
回答不可控，格式随机。

#### One-Shot（单样本）- 给 1 个示例
```
示例：
问：诸葛亮是谁？
答：诸葛亮，字孔明，三国蜀汉丞相，杰出的政治家和军事家。

现在回答：
问：贾宝玉是谁？
```

回答会模仿示例的格式。

#### Few-Shot（少样本）- 给 2-5 个示例
```
示例 1：
问：诸葛亮是谁？
答：诸葛亮，字孔明，三国蜀汉丞相。代表事件：三顾茅庐、草船借箭、空城计。

示例 2：
问：孙悟空是谁？
答：孙悟空，《西游记》主角，花果山美猴王。代表事件：大闹天宫、三打白骨精。

示例 3：
问：林黛玉是谁？
答：林黛玉，《红楼梦》女主角，金陵十二钗之首。代表作品：《葬花吟》。

现在回答：
问：贾宝玉是谁？
```

### Few-Shot 的优势

1. **统一格式** - 所有回答格式一致
2. **控制长度** - 示例多长，回答就多长
3. **控制风格** - 示例什么风格，回答就什么风格
4. **提高准确性** - 模型更理解你的需求

### 实际效果对比

**Zero-Shot 回答**：
```
贾宝玉是《红楼梦》的男主角，荣国府的公子，生来口含宝玉，性格温柔多情，
喜欢和女孩子在一起，不喜欢读书做官，最后出家为僧。
```
风格不统一，长度不可控。

**Few-Shot 回答**：
```
贾宝玉，《红楼梦》男主角，荣国府衔玉而诞的公子。
代表事件：神游太虚幻境、与黛玉相知相恋、宝钗成婚后出家。
```
格式统一，长度适中。

---

## 2. Chain of Thought（思维链，CoT）

### 什么是 CoT？

让模型"一步步思考"，而不是直接给答案。

### 对比示例

**不用 CoT**：
```
问：林黛玉和薛宝钗谁更适合贾宝玉？
答：林黛玉更适合。
```
没有推理过程，不知道为什么。

**使用 CoT**：
```
问：林黛玉和薛宝钗谁更适合贾宝玉？请一步步分析。

答：让我一步步分析：

1. 性格匹配度：
   - 林黛玉：敏感多情，与宝玉心灵相通
   - 薛宝钗：端庄稳重，符合世俗标准

2. 价值观：
   - 林黛玉：反对功名利禄，与宝玉一致
   - 薛宝钗：劝宝玉读书做官，与宝玉相悖

3. 情感基础：
   - 林黛玉：青梅竹马，深厚感情
   - 薛宝钗：家族安排，缺乏感情基础

结论：从性格、价值观、情感基础来看，林黛玉更适合贾宝玉。
```

### CoT 的触发词

- "请一步步分析"
- "让我们逐步思考"
- "请详细推理"
- "Let's think step by step"

---

## 3. RAG（检索增强生成）

### 你的项目正在用的就是 RAG！

RAG = Retrieval（检索）+ Augmented（增强）+ Generation（生成）

### 工作流程

```
用户提问："贾宝玉是谁？"
    ↓
检索向量数据库
    ↓
找到相关文档片段
    ↓
把文档 + 问题一起给 LLM
    ↓
LLM 基于文档生成答案
```

### RAG vs 纯 LLM

**纯 LLM**：
```
问：贾宝玉的结局是什么？
答：贾宝玉最后出家为僧。
```
可能不准确，可能有幻觉。

**RAG**：
```
问：贾宝玉的结局是什么？

检索到的文档：
"宝玉中举后，看破红尘，在雪夜离家出走，
后在船上遇见贾政，拜别后飘然而去，出家为僧。"

答：根据《红楼梦》原文，贾宝玉中举后看破红尘，
在雪夜离家出走，后在船上与父亲贾政告别，出家为僧。
```
准确，有依据。

---

## 4. Fine-tuning（微调）

### 什么是微调？

用你的数据重新训练模型，让它更懂你的领域。

### 微调 vs RAG

| 对比项 | RAG | Fine-tuning |
|--------|-----|-------------|
| 成本 | 低 | 高 |
| 时间 | 快（几分钟） | 慢（几小时到几天） |
| 数据量 | 少（几个文档） | 多（几千到几万条） |
| 更新 | 容易 | 难（重新训练） |
| 适用场景 | 知识库问答 | 特定风格生成 |

### 你的项目应该用哪个？

**答案：RAG！**（已实现）

原因：
1. 四大名著是知识库问答，RAG 最合适
2. 文档会更新，RAG 容易更新
3. 成本低，效果好
4. 无需大量标注数据

---

## 5. 在你的项目中应用

### 当前状态
✅ RAG - 已实现
✅ 关键词优化 - 已实现
⏭️ Few-Shot - 可添加
⏭️ CoT - 可添加

### 优化建议

#### 优化 1：改进 System Prompt

当前（`app/core/agent.py`）：
```python
system_prompt="你是一个智能助手。"
```

优化后：
```python
system_prompt="""你是一位精通中国古典文学的专家，特别擅长四大名著。

回答要求：
1. 基于知识库内容回答，引用原文
2. 回答准确、简洁、有条理
3. 如果知识库没有相关内容，明确告知

回答格式：
- 人物介绍：姓名、身份、性格、主要经历
- 故事情节：起因、经过、结果
"""
```

#### 优化 2：添加 Few-Shot（可选）

创建示例配置，在提示词中加入示例。

#### 优化 3：使用 CoT（复杂问题）

检测到对比、分析类问题时，自动添加"请一步步分析"。

---

## 总结

- **Few-Shot**：给示例，统一格式 ⭐⭐⭐⭐
- **CoT**：一步步思考，提高推理 ⭐⭐⭐⭐
- **RAG**：检索 + 生成，最适合你的项目 ⭐⭐⭐⭐⭐（已实现）
- **Fine-tuning**：重新训练，成本高（不需要）

**你的项目已经用了最适合的 RAG 策略！** 🎉

需要进一步优化可以添加 Few-Shot 和 CoT。
